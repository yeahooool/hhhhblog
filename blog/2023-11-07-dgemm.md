---
slug: dgemm
title: dgemm 使用流程
authors: hf
tags: [BLAS, Fortran]
---

`dgemm` 是 BLAS（Basic Linear Algebra Subprograms）库中的一个函数，它执行**双精度浮点数**矩阵之间的乘法，其功能可以用下面的公式表示：

$$
C := \alpha \cdot op(A) \cdot op(B) + \beta \cdot C
$$

其中：

- $op(A)$表示矩阵`A`或其转置。
- $op(B)$表示矩阵`B`或其转置。
- $\alpha$ 和 $\beta$ 是标量值。
- $C$ 是输出矩阵。

具体来说，函数的参数通常是这样的：

```fortran
dgemm(TRANSA, TRANSB, M, N, K, ALPHA, A, LDA, B, LDB, BETA, C, LDC)
```

各参数含义如下：

| 参数   | 含义                                                                                             |
| ------ | ------------------------------------------------------------------------------------------------ |
| TRANSA | 指定 $A$ 矩阵是否转置，可以是 `N` 或 `T`，分别表示 $op(A) = A$ 和 $op(A) = A^T$                  |
| TRANSB | 指定 $B$ 矩阵是否转置，可以是 `N` 或 `T`，分别表示 $op(B) = B$ 和 $op(B) = B^T$                  |
| M      | 实际运算时 $A$ 矩阵的行数，即 $op(A)$ 矩阵的行数，也是 $C$ 矩阵的行数                            |
| N      | 实际运算时 $B$ 矩阵的列数，即 $op(B)$ 矩阵的列数，也是 $C$ 矩阵的列数                            |
| K      | 实际运算时 $A$ 矩阵的列数和实际运算时 $B$ 矩阵的行数, 即 $op(A)$ 矩阵的列数和 $op(B)$ 矩阵的行数 |
| ALPHA  | 标量乘子 $\alpha$                                                                                |
| A      | 矩阵 $A$                                                                                         |
| LDA    | $A$ 矩阵的前导维度，表示 $A$ 矩阵数据在内存中的存储步长，通常是 $A$ 矩阵（不是$op(A)$）的行数    |
| B      | 矩阵 $B$                                                                                         |
| LDB    | $B$ 矩阵的前导维度，表示 $B$ 矩阵数据在内存中的存储步长，通常是 $B$ 矩阵（不是$op(B)$）的行数    |
| BETA   | 标量乘子 $\beta$                                                                                 |
| C      | 矩阵 $C$                                                                                         |
| LDC    | $C$ 矩阵的前导维度，表示 $C$ 矩阵数据在内存中的存储步长，通常是 $C$ 矩阵的行数                   |

<!-- truncate -->

## 例子

````fortran
! take weights
call dgemm('T', 'N', node_em(ll+1),num,node_em(ll), 1.d0, &
   Wij_em(1,1,ll,itype2,itype1),nodeMM_em,f_out(1,1,ll),nodeMM_em,0.d0,f_in(1,1,ll+1),nodeMM_em)
! add bias
do i=1,num
   do j=1,node_em(ll+1)
      f_in(j,i,ll+1)=f_in(j,i,ll+1)+B_em(j,ll,itype2,itype1)
   enddo
enddo```

表示计算 $W_{ij}^{(em)}$ 矩阵的转置与 $f_{out}^{(em)}$ 矩阵的乘积，结果存储在 $f_{in}^{(em+1)}$ 矩阵中。
该调用可以表示为执行操作$C: = 1.0 \cdot A^T \cdot B + 0.0 \cdot C$

:::note
`Wij_em(1,1,ll,itype2,itype1)`，索引`1, 1`不表示取一个单独的值，而是从这个多维数组的某个位置开始的一个连续的内存块。在 `dgemm` 中使用时，这是告诉 `dgemm` 从哪里开始读取数据。它并不是说只操作一个元素，而是操作以该元素为起点的一整块区域。

`Wij_em(1,1,ll,itype2,itype1)` 实际上指的是这个五维数组中的一个特定的二维矩阵切片。这个切片是从第一行第一列开始的，具体到网络中的第 `ll` 层以及第 `itype2` 类型到第 `itype1` 类型之间的权重矩阵。
:::

## 怎么用？

在线性代数中，特别是在神经网络的计算中，有时会需要将一个偏置向量添加到每一个样本的结果上。标准神经网络中公式为：$ w^T x + b $，其中 $w$ 是权重向量，$x$ 是输入向量，$b$ 是偏置向量。在神经网络中，$w$ 和 $x$ 都是矩阵，$b$ 是一个向量，所以需要将 $b$ 向量添加到每一个样本的结果上。

刚才提到的代码中，首先是一个`dgemm`调用，执行权重矩阵`Wij_em`和输入特征`f_out`之间的矩阵乘法。然后，通过两个嵌套的`do`循环将偏置向量`B_em`添加到结果矩阵`f_in`中。实际上，可以通过`dgemm`调用来完成这个操作，而不需要使用`do`循环。

在调用`dgemm`时，因为`B_em`是一个向量，需要进行重塑或填充，以匹配`f_in`矩阵的形状，使得可以直接相加。

```fortran
allocate(Wij_em(nodeMM_em,nodeMM_em,nlayer_em,iitype_count,iitype_count))
allocate(B_em(nodeMM_em,nlayer_em,iitype_count,iitype_count))
allocate(f_in(nodeMM_em,jjm,nlayer_em+1))
allocate(f_out(nodeMM_em,jjm,nlayer_em+1))

do itype1=1,ntypes
   f_in_NN=0.d0
   ss=0.d0
   d_ss=0.d0
   d_ss_fout=0.d0
   do itype2=1,ntypes
      jj=0
      do i=1,natom_n_type(itype1)
         iat=iat_ind(i,itype1)
         neigh_add=0
         if(iflag_ghost_neigh.eq.1.and.num_neigh(itype2,iat).lt.m_neigh) neigh_add=1
         do j=1,num_neigh(itype2,iat)+neigh_add
            jj=jj+1
            f_in(1,jj,1)=s_neigh(j,itype2,iat)
            f_out(1,jj,1)=s_neigh(j,itype2,iat)
            f_d(1,jj,1,itype2)=1.d0
         enddo
      enddo
      num=jj     ! the same (itype2,itype1), all the neigh, and all the atom belong to this CPU
      do ll=1,nlayer_em
         if (ll.eq.2) then
            write(*,*) "Wij_em", Wij_em(1,1,ll,itype2,itype1)
            write(*,*) "f_out", f_out(1,1,ll)
            write(*,*) "B_em", B_em(1,ll,itype2,itype1)
         endif

         ! take weights
         call dgemm('T', 'N', node_em(ll+1),num,node_em(ll), 1.d0, &
            Wij_em(1,1,ll,itype2,itype1),nodeMM_em,f_out(1,1,ll),nodeMM_em,0.d0,f_in(1,1,ll+1),nodeMM_em)
         ! add bias
         do i=1,num
            do j=1,node_em(ll+1)
               f_in(j,i,ll+1)=f_in(j,i,ll+1)+B_em(j,ll,itype2,itype1)
            enddo
         enddo
....
````

:::info
要使用 `dgemm` 替换掉显式的偏置添加循环，我们可以想象这样一个计算图：

1. 输入特征矩阵(`f_out`)：在每一层`ll`的计算开始时，`f_out`包含输入特征，经过索引切片后，其维度为`[node_em(ll), num]`。
2. 权重矩阵(`Wij_em`)：在每一层`ll`的计算开始时，`Wij_em`包含权重矩阵，经过索引切片及转置后，是一个二维数组，其维度为`[node_em(ll+1), node_em(ll)]`。
3. 偏置向量(`B_em`)：是一个一维数组，其维度为`[node_em(ll+1)]`。
4. 输出特征矩阵(`f_in`)：这是输出特征的存储位置，其维度为`[node_em(ll+1), num]`。

在每次计算中，`dgemm` 完成了以下操作：`f_in(ll+1)` = `Wij_em(ll)` \* `f_out(ll)` + `B_em(ll)`。在标准的 `dgemm` 调用中，`C` 矩阵在乘法后添加到结果上，因此我们可以把偏置向量 `B_em` 转换成适当的矩阵形式，以便通过这种方式加入。

要做到这一点，我们可以创建一个全是`1`的临时向量，并将其和 `B_em` 相乘，形成一个每一行都是 `B_em` 的矩阵。但是这可以通过巧妙地设置 `dgemm` 的参数来避免显式创建这个`全1向量`。**(B_em 的维度`[node_em(ll+1)]` --> `[node_em(ll+1), num]`)**
:::

具体来说，已经执行了权重矩阵`Wij_em`和输入矩阵`f_out`的乘法，输出结果存储在`f_in`中。然后将偏置通过一个嵌套循环直接加到`f_in`的每一行上的。

为了同时实现加法，我们将使用一个全是 1 的临时矩阵与`B_em`相乘来创建一个每行都是`B_em`的矩阵，然后将这个矩阵加到`f_in`中。为了实现这一点，我们首先需要分配一个临时全 1 矩阵：

```fortran
! 分配一个全1的临时矩阵
allocate(ones(1, num))
ones(:,:) = 1.d0
```

现在，使用`dgemm`来将偏置加到`f_in`上：

```fortran
! 使用dgemm将偏置加到f_in上
call dgemm('N', 'N', node_em(ll+1), num, 1, 1.d0, &
   B_em(1, ll, itype2, itype1), node_em(ll+1), ones, 1, 1.d0, f_in(1, 1, ll+1), nodeMM_em)
```

在这个`dgemm`调用中，`ones`矩阵起到了创建每列都是`B_em`的副本的作用。`alpha`和`beta`都设置为 1.d0 以保持原有的 `f_in` 值并加上新的偏置矩阵。这个调用中，`B_em` 实际上是被当作一个列矩阵来使用的，它与每一列都是 1 的行矩阵相乘，最终得到一个每一行都是 `B_em` 的矩阵。然后这个矩阵加到了 `f_in` 的相应层上。

$$
\begin{bmatrix}
   x_1  \\
   x_2  \\
    x_3  \\
    x_4  \\
    ..  \\
    x_{ll+1}
\end{bmatrix}

\times

\begin{bmatrix}
   y_1 & y_2 & y_3 & y_4 & .. & y_{num}
\end{bmatrix}

=

\begin{bmatrix}
   x_1 y_1 & x_1 y_2 & x_1 y_3 & x_1 y_4 & .. & x_1 y_{num} \\
   x_2 y_1 & x_2 y_2 & x_2 y_3 & x_2 y_4 & .. & x_2 y_{num} \\
   x_3 y_1 & x_3 y_2 & x_3 y_3 & x_3 y_4 & .. & x_3 y_{num} \\
   x_4 y_1 & x_4 y_2 & x_4 y_3 & x_4 y_4 & .. & x_4 y_{num} \\
   .. & .. & .. & .. & .. & .. \\
   x_{ll+1} y_1 & x_{ll+1} y_2 & x_{ll+1} y_3 & x_{ll+1} y_4 & .. & x_{ll+1} y_{num} \\
\end{bmatrix}


$$

:::note
如果`B_em`是一个列向量，我们可以创建一个形状为`(num, 1)`的全 1 矩阵。
:::
