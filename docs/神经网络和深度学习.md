# 基本概念
## Perceptron
1. 什么是神经网络？
2. artificial neuron (perceptron)
3. sigmoid neurons
4. 一个perceptron如何工作？每一个输入的值，给予相应的权重，用加权和是否大于或小于某个阈值（期望值）来判断输出的值。
5. 我们可以设计出学习算法，该算法可以自动调整人工神经元网络的权重和bias（阈值的另外一种简化表示方式，$bias \equiv -threshold$）。这种调整是对外部刺激的反应，无需程序员的直接干预。
6. $\omega x + b$

## Sigmoid neurons
1. 权重或bias的小变化，只引起输出的小变化。基于该可能实现的事实，可以进行负反馈调整网络。**问题是**：基于perceptron的网络，一个小的变化可能会引起输出的翻转。
2. 引入$sigmoid$ $function*$, $\sigma \equiv \frac{1}{1+e^{-z}}$, 输入不再限于0和1，可以为0-1之间的任何值。
3. 相当于阶跃函数的平滑版本。
4. $\sigma(\omega x + b)$
5. activation function

## The architecture of neural networks
以下正反馈神经网络：
1. input layer - input neurons
2. hidden layer - **How to design it**
3. output layer - output neurons
缺乏负反馈过程，输入已经决定了输出。

### Recurrent neural networks
feedback loop
一定时间内，散播式刺激神经元

## gradient descent
1. cost function - 一个均方差函数，表示值越小，表明训练算法越好。缺点是无法处理大量数据。
2. 通过一组权重和bias,使cost function尽可能小 --- 利用gradient descent算法
### 梯度下降
需要理解几个概念
1. 微分：
   * 函数图像中，某点切线的斜率
   * 函数的变化率
2. 梯度：多变量微分的一般化，就是分别对每个变量进行微分。其实就是一个向量，向量有方向，梯度的方向表示了函数在给定点的上升最快的方向。那么梯度的反方向就算函数在给定点下降最快的方向。
3. 想象一个山坡，你需要在太阳下山前（时间）到达山谷（**global minimum**），那么需要找到一个最快的路径。根据梯度下降的方式，选取随机的一个位置为基准，寻找这个位置最陡峭的地方（**局部梯度最小值**），然后朝着山的高度下降的地方走。每走一段距离，都反复用同一个方法寻找最陡峭的地方。但是为了在太阳下山前到达，需要尽可能地减少测量方向的次数，测少可能偏离轨道，测多耽误时间，需要做的就是找到一个合适的测量方向的频率（**学习率**$\eta$，步长，太大，可能会错过局部最小值，太小，花费的时间太长）。
4. gradient descent update rule: $v^{'} = v - \eta \nabla C$

# how the backpropagation algorithm works
1. 目的是计算cost function C相对于网络中任何weight或bias的偏导。
2. l层神经元的加权输入的简化表达式：$a^l = \sigma (\omega^l a^{l-1} + b^l)$
This expression gives us a much more global way of thinking about how the activations in one layer relate to activations in the previous layer: we just apply the weight matrix to the activations, then add the bias vector, and finally apply the $\sigma$ function*.
## 关于cost function的两个假设
1. 1
2. 2
## the four fundamental equations behind backpropagation
定义一个误差项$\delta^l_j$，作用于加权输入。
1. error in the output layer
2. error in the next layer
3. error in the rate of change of the cost with respect to any bias
4. error in the rate of change of the cost with respect to any weight

## the backpropagation algorithm
1. **input x:** 为输入layer设置相应的activation $a^1$.
2. **Feedforward:** 为每个$l = 2,3,...,L$计算$z^l = \omega^l a^{l-1} + b^l$和$a^l = \sigma(z^l)$.
3. **Output error $\delta^L$:** 计算矢量$\delta^L = \nabla_a C \odot \sigma^{'}(z^L)$.
4. **Backpropagate the error:** 为每个$l = L-1, L-2,...,2$计算$\delta^l = ((\omega^{l+1})^T \delta^{l+1}) \odot \sigma^{'}(z^l)$.
5. **Output:** cost function的梯度由下式给出：$\frac{\partial C}{\partial \omega^l_{jk}} = a^{l-1}_k \delta^l_j$和$\frac{\partial C}{\partial b^l_j} = \delta^l_j$.
   * 实际使用时结合梯度下降法，比如更新biases的取值根据规则：$b^l \rightarrow b^l - \frac{\eta}{m} \sum_x \delta^l$, 
   * 更新weights的规则：$\omega^l \rightarrow \omega^l - \frac{\eta}{m} \sum_x \delta^l (a^{l-1})^T$.

反向传播算法可以追踪weight和bias的小扰动。

# Improving the way
## the cross-entropy cost function
$C = - \frac{1}{n} \sum_x[y\ln a + (1-y)\ln(1-a)] $
可以理解为每个神经元交叉熵的总和，每个神经元的activation被解释为两元素概率分布的一部分。一个由该神经元的activation a和它的补集1-a组成的概率分布。

## softmax
softmax layer的输出可以看作是一个概率分布。The idea of softmax is to define a new type of output layer for our neural networks.

## overfitting and regularization
为了有效训练，需要一种方法来检测何时发生了过度拟合，以便我们不会过度训练。
如在训练过程中，对测试数据的准确性进行跟踪。
### Regularization
* weight decay: $(1 - \frac{\eta \lambda}{n})\omega$
* L2 regularization: $C = C_0 + \frac{\lambda}{2n} \sum_\omega \omega^2$. Regularization can be viewed as a way of compromising between finding small weights and minimizing the original cost function.

## Weight initialization
解决过饱和问题，从而避免学习速度下降。

## How to choose a neural network's hyper-parameters?
1. **Broad strategy:** **增加检测数据的频率再逐渐减小**，降低用于验证的训练数据。
2. **Learning rate:** **估计阈值的数量级**。First, we estimate the threshold value for η at which the cost on the training data immediately begins decreasing, instead of oscillating or increasing. This estimate doesn't need to be too accurate. You can estimate the order of magnitude by starting with η=0.01. If the cost decreases during the first few epochs, then you should successively try η=0.1,1.0,… until you find a value for η where the cost oscillates or increases during the first few epochs. Alternately, if the cost oscillates or increases during the first few epochs when η=0.01, then try η=0.001,0.0001,… until you find a value for η where the cost decreases during the first few epochs. Following this procedure will give us an order of magnitude estimate for the threshold value of η. 
3. **Use early stopping to detemine the number of training epochs:** **在每个epoch结束时，计算validation data的分类精度**。A better rule is to terminate if the best classification accuracy doesn't improve for quite some time.
4. **Learning rate schedule:** 使用一个大的学习率$\eta$，使weights快速变化。之后降低学习率，对Weights进行精细地调整。
5. **The regularization paramater, $\lambda$:** 建议最初从无regularization($\lambda = 0$)开始，并如上所述确定一个$\eta$值。
6. **Mini-batch size:** Plot the validation accuracy versus time (as in, real elapsed time, not epoch!), and choose whichever mini-batch size gives you the most rapid improvement in performance. With the mini-batch size chosen you can then proceed to optimize the other hyper-parameters.
7. **Automated techniques:** 
   * grid search 